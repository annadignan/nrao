{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ce86bc8",
   "metadata": {},
   "source": [
    "# Loading in csv file with photometry results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a13dc556",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import statements\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from astropy.io import ascii\n",
    "from astropy.table import join\n",
    "from astropy.table import Table, vstack\n",
    "\n",
    "#read in csv file with photometry results\n",
    "phot=ascii.read('/users/adignan/csv/photometry_results.csv',format='csv')\n",
    "\n",
    "#modify both Tables (rename columns, calculate nondetections vs detections)\n",
    "phot['SNR > 3?'] = ['YES' if x > 3 else 'NO' for x in phot['SNR']]\n",
    "photmod=phot[['Source ID','freq (GHz)','flux density (mJy)','error (mJy)','SNR > 3?']]\n",
    "\n",
    "names=('Source ID','freq (GHz)','flux density (mJy)','error (mJy)','SNR > 3?')\n",
    "new_names=('sourceid','freq','flux','error','snr_ratio')\n",
    "\n",
    "photmod.rename_columns(names,new_names)\n",
    "\n",
    "#make a dataframe version of our astropy Table so we can do conditional stuff below\n",
    "photmod=Table.to_pandas(photmod)\n",
    "\n",
    "# np.select and define list of condition with corresponding values\n",
    "photmod['data']=(np.select([photmod['snr_ratio'].eq('YES'), # condition #1\n",
    "                         photmod['snr_ratio'].eq('NO')],# condition #2\n",
    "                        [photmod['flux'],            # value when #1 is true\n",
    "                         3*photmod['error']]))           # value when #2 is true\n",
    "\n",
    "photmod['data_err']=(np.select([photmod['snr_ratio'].eq('YES'), # condition #1\n",
    "                         photmod['snr_ratio'].eq('NO')], # condition #2\n",
    "                        [photmod['error'], # value when #1 is true\n",
    "                         0.0]))        # value when #2 is true\n",
    "\n",
    "photmod['lims']=(np.select([photmod['snr_ratio'].eq('YES'), # condition #1\n",
    "                        photmod['snr_ratio'].eq('NO')], # condition #2\n",
    "                        [False, # value when #1 is true\n",
    "                         True]))       # value when #2 is true\n",
    "\n",
    "photmod['marker']=(np.select([photmod['snr_ratio'].eq('YES'), # condition #1\n",
    "                         photmod['snr_ratio'].eq('NO')], # condition #2\n",
    "                        ['o', # value when #1 is true\n",
    "                         'o']))       # value when #2 is true\n",
    "\n",
    "#############################################################################################\n",
    "\n",
    "#read in csv file with photometry results\n",
    "# old_df = pd.read_csv('/users/adignan/csv/NEW_photometry_results.csv')\n",
    "# # old_data=old_df[old_df['source ID'].str.contains('NGC2146')] #we want just NGC5194 sources!\n",
    "\n",
    "# oldphot=Table.from_pandas(old_data)\n",
    "\n",
    "# #modify both Tables (rename columns, calculate nondetections vs detections)\n",
    "# oldphot['SNR > 3?'] = ['YES' if x > 3 else 'NO' for x in oldphot['SNR']]\n",
    "# oldphotmod=oldphot[['source ID','freq (GHz)',\n",
    "#                     'flux density (mJy)','error (mJy)','SNR > 3?']]\n",
    "\n",
    "# old_new_names=('sourceid','freq','old_flux','old_error','old_snr_ratio')\n",
    "\n",
    "# oldphotmod.rename_columns(names,old_new_names)\n",
    "\n",
    "# #make a dataframe version of our astropy Table so we can do conditional stuff below\n",
    "# oldphotmod=Table.to_pandas(oldphotmod)\n",
    "\n",
    "# # np.select and define list of condition with corresponding values\n",
    "# oldphotmod['old_data']=(np.select([oldphotmod['old_snr_ratio'].eq('YES'), # condition #1\n",
    "#                          oldphotmod['old_snr_ratio'].eq('NO')],# condition #2\n",
    "#                         [oldphotmod['old_flux'],            # value when #1 is true\n",
    "#                          3*oldphotmod['old_error']]))           # value when #2 is true\n",
    "\n",
    "# oldphotmod['old_data_err']=(np.select([oldphotmod['old_snr_ratio'].eq('YES'), # condition #1\n",
    "#                          oldphotmod['old_snr_ratio'].eq('NO')], # condition #2\n",
    "#                         [oldphotmod['old_error'], # value when #1 is true\n",
    "#                          0.0]))        # value when #2 is true\n",
    "\n",
    "# oldphotmod['old_lims']=(np.select([oldphotmod['old_snr_ratio'].eq('YES'), # condition #1\n",
    "#                         oldphotmod['old_snr_ratio'].eq('NO')], # condition #2\n",
    "#                         [False, # value when #1 is true\n",
    "#                          True]))       # value when #2 is true\n",
    "\n",
    "# oldphotmod['old_marker']=(np.select([oldphotmod['old_snr_ratio'].eq('YES'), # condition #1\n",
    "#                          oldphotmod['old_snr_ratio'].eq('NO')], # condition #2\n",
    "#                         ['s', # value when #1 is true\n",
    "#                          's']))       # value when #2 is true\n",
    "\n",
    "# # ids=['NGC0337a','NGC0337b','NGC0337d]\n",
    "\n",
    "# # df_filt = df[df.sourceid.isin(ids)]\n",
    "\n",
    "# merged_df = photmod.merge(oldphotmod, how = 'inner', \n",
    "#                           on = ['sourceid','freq'])\n",
    "\n",
    "# merged_df\n",
    "#go ahead and remove NGC4631Enuc.1 from our table so it doesn't cause trouble later on\n",
    "# photmod=photmod[photmod['sourceid']!='NGC4631Enuc.1']\n",
    "photmod.to_csv('/users/adignan/photmod_july.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665ae4ab",
   "metadata": {},
   "source": [
    "# Creating plots of fluxes for each source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb4a449",
   "metadata": {},
   "source": [
    "## Spectral index fitting (CURRENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fef9d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.odr import ODR, Model, RealData\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "#read in data csv file\n",
    "photmod=pd.read_csv('/users/adignan/photmod_july.csv')\n",
    "\n",
    "#initialize empty lists\n",
    "alpha1vals=[]\n",
    "unc1vals=[]\n",
    "\n",
    "alpha2vals=[]\n",
    "unc2vals=[]\n",
    "\n",
    "alpha3vals=[]\n",
    "unc3vals=[]\n",
    "\n",
    "# linear function\n",
    "def linear_func(beta, x):\n",
    "    return beta[0] * x + beta[1]\n",
    "\n",
    "# Example data points\n",
    "x = photmod.freq[0:3]\n",
    "y = photmod.flux[0:3]\n",
    "y_err = photmod.error[0:3]  # Uncertainties in y\n",
    "\n",
    "\n",
    "data = RealData(np.log10(x), np.log10(y), sy=np.log10(y_err))\n",
    "linear_model = Model(linear_func)\n",
    "\n",
    "# Create an ODR object\n",
    "odr = ODR(data, linear_model, beta0=[1., 1.])  # Initial guess for slope and intercept\n",
    "\n",
    "# Run the regression\n",
    "output = odr.run()\n",
    "\n",
    "# Extract the parameters and their uncertainties\n",
    "slope, intercept = output.beta\n",
    "slope_err, intercept_err = output.sd_beta\n",
    "\n",
    "# Print results\n",
    "print(f\"Slope: {slope} +/- {slope_err}\")\n",
    "print(f\"Intercept: {intercept} +/- {intercept_err}\")\n",
    "\n",
    "for i in range(photmod.sourceid.nunique()):\n",
    "    \n",
    "        #3 to 33 GHz\n",
    "        data1=photmod[i*4:i*4+3]\n",
    "        index1 = data1[data1['snr_ratio'] == 'NO'].index\n",
    "\n",
    "        #33 to 90 GHz\n",
    "        data2=photmod[i*4+2:i*4+4]\n",
    "        index2 = data2[data2['snr_ratio'] == 'NO'].index\n",
    "        \n",
    "        #3 to 90 GHz\n",
    "        data3=photmod[i*4:i*4+4]\n",
    "        index3 = data3[data3['snr_ratio'] == 'NO'].index\n",
    "        \n",
    "        #don't fit for 3 to 33 GHz if we don't have enough detections\n",
    "        if ((len(index1)) == 3) or ((len(index1)) == 2):\n",
    "            slope1, intercept1 = [np.nan, np.nan]\n",
    "            slope_err1, intercept_err1 = [np.nan, np.nan]\n",
    "        #fit if we have enough detections\n",
    "        if ((len(index1)) == 1) or ((len(index1)) == 0):\n",
    "\n",
    "            data = RealData(x=np.log10(data1.freq.tolist()), \n",
    "                            y=np.log10(data1.flux.tolist()), \n",
    "                            sy=np.log10(data1.error.tolist()))\n",
    "            linear_model = Model(linear_func)\n",
    "\n",
    "            # Create an ODR object\n",
    "            odr = ODR(data, linear_model, beta0=[1., 1.])  # Initial guess for slope and intercept\n",
    "\n",
    "            # Run the regression\n",
    "            output1 = odr.run()\n",
    "\n",
    "            # Extract the parameters and their uncertainties\n",
    "            slope1, intercept1 = output1.beta\n",
    "            slope_err1, intercept_err1 = output1.sd_beta\n",
    "            \n",
    "        #don't fit for 33 to 90 GHz if we don't have enough detections        \n",
    "        if (len(index2)) != 0:\n",
    "            slope2, intercept2 = [np.nan, np.nan]\n",
    "            slope_err2, intercept_err2 = [np.nan, np.nan]\n",
    "        #fit if we have enough detections\n",
    "        else:\n",
    "            data = RealData(x=np.log10(data2.freq.tolist()), \n",
    "                            y=np.log10(data2.flux.tolist()), \n",
    "                            sy=np.log10(data2.error.tolist()))\n",
    "            linear_model = Model(linear_func)\n",
    "\n",
    "            # Create an ODR object\n",
    "            odr = ODR(data, linear_model, beta0=[1., 1.])  # Initial guess for slope and intercept\n",
    "\n",
    "            # Run the regression\n",
    "            output2 = odr.run()\n",
    "\n",
    "            # Extract the parameters and their uncertainties\n",
    "            slope2, intercept2 = output2.beta\n",
    "            slope_err2, intercept_err2 = output2.sd_beta\n",
    "            \n",
    "        #don't fit for 3 to 90 GHz if we don't have enough detections\n",
    "        if ((len(index3)) == 4) or ((len(index3)) == 3):\n",
    "            slope3, intercept3 = [np.nan, np.nan]\n",
    "            slope_err3, intercept_err3 = [np.nan, np.nan]\n",
    "        #fit if we have enough detections\n",
    "        if ((len(index3)) == 2) or ((len(index3)) == 1) or ((len(index3)) == 0):\n",
    "            data = RealData(x=np.log10(data3.freq.tolist()), \n",
    "                            y=np.log10(data3.flux.tolist()), \n",
    "                            sy=np.log10(data3.error.tolist()))\n",
    "            linear_model = Model(linear_func)\n",
    "\n",
    "            # Create an ODR object\n",
    "            odr = ODR(data, linear_model, beta0=[1., 1.])  # Initial guess for slope and intercept\n",
    "\n",
    "            # Run the regression\n",
    "            output3 = odr.run()\n",
    "\n",
    "            # Extract the parameters and their uncertainties\n",
    "            slope3, intercept3 = output3.beta\n",
    "            slope_err3, intercept_err3 = output3.sd_beta\n",
    "        \n",
    "        #save unpacked results!\n",
    "        alpha1vals.append(slope1)\n",
    "        unc1vals.append(slope_err1)\n",
    "            \n",
    "        alpha2vals.append(slope2)\n",
    "        unc2vals.append(slope_err2)\n",
    "        \n",
    "        alpha3vals.append(slope3)\n",
    "        unc3vals.append(slope_err3)\n",
    "\n",
    "        i=+4\n",
    "        \n",
    "#make a dataframe of the results\n",
    "\n",
    "specdf = pd.DataFrame(np.column_stack([photmod['sourceid'].unique(), \n",
    "                                       alpha1vals, unc1vals, alpha2vals, unc2vals, \n",
    "                                       alpha3vals, unc3vals]), \n",
    "                               columns=['source ID', 'alpha1', 'unc1',\n",
    "                                        'alpha2','unc2', 'alpha3', 'unc3'])\n",
    "\n",
    "#save dataframe as csv\n",
    "specdf.to_csv('/users/adignan/specdf_july_test2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2d0915",
   "metadata": {},
   "source": [
    "## Spectral index fitting (OLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "37a1d495",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/adignan/anaconda3/lib/python3.11/site-packages/scipy/optimize/_minpack_py.py:1010: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  warnings.warn('Covariance of the parameters could not be estimated',\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "import sys\n",
    "import pdb\n",
    "\n",
    "alpha1vals=[]\n",
    "b1vals=[]\n",
    "alpha1err=[]\n",
    "\n",
    "alpha2vals=[]\n",
    "b2vals=[]\n",
    "alpha2err=[]\n",
    "\n",
    "alphavals=[]\n",
    "bvals=[]\n",
    "\n",
    "def func_fit(a,x,b):\n",
    "    return a*x + b\n",
    "\n",
    "for i in range(photmod.sourceid.nunique()):\n",
    "    \n",
    "        \n",
    "        #3 to 33 GHz\n",
    "        data1=photmod[i*4:i*4+3]\n",
    "        index1 = data1[data1['snr_ratio'] == 'NO'].index\n",
    "\n",
    "        #33 to 90 GHz\n",
    "        data2=photmod[i*4+2:i*4+4]\n",
    "        index2 = data2[data2['snr_ratio'] == 'NO'].index\n",
    "        \n",
    "        #3 to 90 GHz\n",
    "        data3=photmod[i*4:i*4+4]\n",
    "        index3 = data3[data3['snr_ratio'] == 'NO'].index\n",
    "        \n",
    "        #don't fit for 3 to 33 GHz if we don't have enough detections\n",
    "        if ((len(index1)) == 3) or ((len(index1)) == 2):\n",
    "            popt1 = [np.nan, np.nan]\n",
    "            pcov1 = np.empty((2,2))\n",
    "            pcov1[:] = np.nan\n",
    "            perr1 = np.sqrt(np.diag(pcov1))\n",
    "#             print(perr1)\n",
    "        #fit if we have enough detections\n",
    "        if ((len(index1)) == 1) or ((len(index1)) == 0):\n",
    "            data1=data1.drop(index1,axis=0)\n",
    "            popt1, pcov1 = curve_fit(f=func_fit, xdata=np.log10(data1.freq.tolist()), \n",
    "                                     ydata=np.log10(data1.flux.tolist()),\n",
    "                                     sigma=np.log10(data1.error),\n",
    "                                     absolute_sigma=True)\n",
    "            perr1 = np.sqrt(np.diag(pcov1))\n",
    "#             print('data: '+str(data1))\n",
    "#             print('input error '+str(0.434*(np.log10(data1.error)/np.log10(data1.flux))))\n",
    "#             print('covariance matrix: ' + str(pcov1))\n",
    "#             print('error on fit '+ str(perr1))\n",
    "        #don't fit for 33 to 90 GHz if we don't have enough detections        \n",
    "        if (len(index2)) != 0:\n",
    "            popt2 = [np.nan, np.nan]\n",
    "            pcov2 = np.empty((2,2))\n",
    "            pcov2[:] = np.nan\n",
    "            perr2 = np.sqrt(np.diag(pcov2))\n",
    "        #fit if we have enough detections\n",
    "        else:\n",
    "            popt2, pcov2 = curve_fit(f=func_fit, xdata=np.log10(data2.freq.tolist()), \n",
    "                                     ydata=np.log10(data2.flux.tolist()),\n",
    "                                     sigma=0.434*(np.log10(data2.error)/(np.log10(data2.flux))))\n",
    "            perr2 = np.sqrt(np.diag(pcov2))\n",
    "        #don't fit for 3 to 90 GHz if we don't have enough detections\n",
    "        if ((len(index3)) == 4) or ((len(index3)) == 3):\n",
    "            popt3 = [np.nan, np.nan]\n",
    "            pcov3 = np.empty((2,2))\n",
    "            pcov3[:] = np.nan\n",
    "            perr3 = np.sqrt(np.diag(pcov3))\n",
    "        #fit if we have enough detections\n",
    "        if ((len(index3)) == 2) or ((len(index3)) == 1) or ((len(index3)) == 0):\n",
    "            data3=data3.drop(index3,axis=0)\n",
    "            popt3, pcov3 = curve_fit(f=func_fit, xdata=np.log10(data3.freq.tolist()), \n",
    "                                     ydata=np.log10(data3.flux.tolist()),\n",
    "                                     sigma=0.434*(np.log10(data3.error)/np.log10(data3.flux)))\n",
    "            \n",
    "            perr3 = np.sqrt(np.diag(pcov3))\n",
    "            \n",
    "#             if False in np.isfinite(perr3):\n",
    "                \n",
    "#                 pdb.set_trace()\n",
    "            \n",
    "        #unpack the fitting results\n",
    "        alpha1,b1=popt1\n",
    "        alpha2,b2=popt2\n",
    "        alpha3,b3=popt3\n",
    "        \n",
    "        #save unpacked results!\n",
    "        alpha1vals.append(alpha1)\n",
    "        b1vals.append(perr1[0])\n",
    "            \n",
    "        alpha2vals.append(alpha2)\n",
    "        b2vals.append(perr2[0])\n",
    "        \n",
    "        alphavals.append(alpha3)\n",
    "        bvals.append(perr3[0])\n",
    "\n",
    "        i=+4\n",
    "        \n",
    "#make a dataframe of the results\n",
    "\n",
    "specdf = pd.DataFrame(np.column_stack([photmod['sourceid'].unique(), \n",
    "                                       alpha1vals, b1vals, alpha2vals, b2vals, \n",
    "                                       alphavals, bvals]), \n",
    "                               columns=['source ID', 'alpha1', 'b1',\n",
    "                                        'alpha2','b2', 'alpha', 'b'])\n",
    "\n",
    "#save dataframe as csv\n",
    "# specdf.to_csv('/users/adignan/specdf_july_test1.csv')\n",
    "# print(type(specdf))\n",
    "# photmod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8f5ce4",
   "metadata": {},
   "source": [
    "## Actual plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "59c72ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    }
   ],
   "source": [
    "def func_plot(x,a,b):\n",
    "    return (x**a) * (10**b)\n",
    "\n",
    "for i in range(photmod.sourceid.nunique()):\n",
    "\n",
    "        data=photmod[i*4:i*4+4]\n",
    "        if data.sourceid[i*4]=='NGC4631Enuc.1':\n",
    "            continue\n",
    "        else:\n",
    "            title=data.sourceid[i*4]\n",
    "\n",
    "            plt.figure()\n",
    "\n",
    "\n",
    "            for idx in data.index.tolist():\n",
    "                plt.errorbar(data.freq[idx],data.data[idx],yerr=data.error[idx],marker=data.marker[idx],uplims=data.lims[idx])\n",
    "\n",
    "            if np.isnan(specdf.alpha1[i]):\n",
    "                plt.plot(np.array(data.freq),func_plot(a=specdf.alpha1[i],x=np.array(data.freq),b=specdf.b1[i]),\n",
    "                        label='_nolegend_')\n",
    "            else:\n",
    "                plt.plot(np.array(data.freq),func_plot(a=specdf.alpha1[i],x=np.array(data.freq),b=specdf.b1[i]),\n",
    "                        label='$α_{3–33 GHz}$'+'='+'{:0.2}'.format(specdf.alpha1[i])+'±'+'{:0.2}'.format(specdf.b1[i]))\n",
    "\n",
    "            if np.isnan(specdf.alpha2[i]):\n",
    "                plt.plot(np.array(data.freq),func_plot(a=specdf.alpha2[i],x=np.array(data.freq),b=specdf.b2[i]),\n",
    "                        label='_nolegend_')\n",
    "            else:\n",
    "                plt.plot(np.array(data.freq),func_plot(a=specdf.alpha2[i],x=np.array(data.freq),b=specdf.b2[i]),\n",
    "                        label='$α_{33–90 GHz}$'+'='+'{:0.2}'.format(specdf.alpha2[i])+'±'+'{:0.2}'.format(specdf.b2[i]))\n",
    "\n",
    "        #         if np.isnan(specdf.alpha[i]):\n",
    "        #             plt.plot(np.array(data.freq),func_plot(a=specdf.alpha[i],x=np.array(data.freq),b=specdf.b[i]),\n",
    "        #                     label='_nolegend_')\n",
    "        #         else:\n",
    "        #             plt.plot(np.array(data.freq),func_plot(a=specdf.alpha[i],x=np.array(data.freq),b=specdf.b[i]),\n",
    "        #                     label='$α_{3–90 GHz}$'+'='+'{:0.2}'.format(specdf.alpha[i])+'±'+'{:0.2}'.format(specdf.b[i]))\n",
    "\n",
    "\n",
    "            plt.xticks([3,15,33,90])\n",
    "            plt.xlabel('frequency (GHz)')\n",
    "            plt.ylabel('flux density (mJy)')\n",
    "            plt.yscale('log')\n",
    "            plt.xscale('log')\n",
    "            plt.title(title)\n",
    "            plt.legend()\n",
    "\n",
    "            plt.savefig('/users/adignan/specfits/'+str(data.sourceid[i*4])+'.png',bbox_inches = \"tight\")\n",
    "\n",
    "            plt.close('all')\n",
    "\n",
    "            i=+4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83debc1",
   "metadata": {},
   "source": [
    "# Reproducing Abigail's histogram of spectral index values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd54e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "specdf=pd.read_csv('/users/adignan/csv/specdfcomplete.csv')\n",
    "\n",
    "bins=np.histogram(np.hstack((specdf['alpha1'].dropna(),specdf['alpha2'].dropna())), bins=10)[1] \n",
    "\n",
    "\n",
    "plt.hist(specdf['alpha1'].dropna(),label='$α_{3–33 GHz}$',histtype='step',color='#1f77b4',bins=bins)\n",
    "plt.hist(specdf['alpha2'].dropna(),label='$α_{33–90 GHz}$',histtype='step',color='#ff7f0e',bins=bins)\n",
    "\n",
    "plt.legend()\n",
    "# plt.title('bins=10 (default)')\n",
    "plt.xlabel('spectral index (α)')\n",
    "plt.ylabel('number')\n",
    "plt.axvline(np.median(specdf['alpha1'].dropna()),label='median $α_{3–33 GHz}$: -0.258',\n",
    "            color='#1f77b4',linestyle='-.')\n",
    "plt.axvline(np.median(specdf['alpha2'].dropna()),label='median $α_{33–90 GHz}$: -0.113',\n",
    "            color='#ff7f0e',linestyle='-.')\n",
    "# plt.axvline(np.median(specdf['alpha']),label='median $α_{3–90 GHz}$')\n",
    "plt.legend()\n",
    "\n",
    "print(np.median(specdf['alpha1']))\n",
    "print(np.median(specdf['alpha2'].dropna()))\n",
    "# print(np.median(specdf['alpha']))\n",
    "\n",
    "#'#1f77b4', '#ff7f0e', '#2ca02c',\n",
    "\n",
    "print(len(specdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a99e80-f8e0-46af-b87f-6668cad1db9b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Calculating thermal fraction based on fitting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b0472206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  source ID           data               error        \n",
      "------------- ------------------- --------------------\n",
      "     NGC0337a  0.3026161165873144   0.3967941638508259\n",
      "     NGC0337b  0.1975276275302447   0.6563770375383026\n",
      "     NGC0337c 0.41888283127718073 0.053274200047035376\n",
      "     NGC0337d  0.5674028473328403  0.02601826306095671\n",
      "      NGC0628                 nan                  nan\n",
      "NGC0628Enuc.1  0.3664876333899007  0.22321723706624913\n",
      "NGC0628Enuc.2   0.554464653249289   0.2181909242982021\n",
      "NGC0628Enuc.3  0.5352483369883572   0.0607496150426901\n",
      "NGC0628Enuc.4  0.4384973772180985   0.3666001353577992\n",
      "      NGC0925  0.7513182178914195   1.0500501155547046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_387282/1224420362.py:45: UserWarning: Warning: converting a masked element to nan.\n",
      "  if math.isnan(row['alpha1']) == True:\n"
     ]
    }
   ],
   "source": [
    "from astropy.io import ascii\n",
    "from astropy.table import join\n",
    "from astropy.table import Table, vstack, Column\n",
    "from astropy.stats import median_absolute_deviation\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "x=float('nan')\n",
    "\n",
    "# table1=ascii.read('/users/adignan/specdf_take2.csv',format='csv')\n",
    "# table2=ascii.read('/users/adignan/newspecdf.csv',format='csv')\n",
    "# table3=vstack([table1, table2], join_type='exact')\n",
    "# table3.write('/users/adignan/specdfcomplete.csv',overwrite=True)\n",
    "table=ascii.read('/users/adignan/specdf_july.csv',format='csv')\n",
    "\n",
    "def tfrac(alpha):\n",
    "    fraction=( (3/33)**(-alpha) - (3/33)**(0.85) )/( (3/33)**(-0.1) - (3/33)**(0.85) )\n",
    "    return fraction \n",
    "\n",
    "def tfrac_unc(alpha,unc):\n",
    "    # Constants\n",
    "    nu1 = 33  # GHz\n",
    "    nu2 = 3   # GHz\n",
    "    alpha_NT = -0.85 \n",
    "    sigma_alpha_NT = 0\n",
    "    # Calculated values\n",
    "    A = (nu2 / nu1) ** (-alpha)\n",
    "    B = (nu2 / nu1) ** (-alpha_NT)\n",
    "    C = (nu2 / nu1) ** (-0.1)\n",
    "    ln_term = np.log(nu2 / nu1)\n",
    "\n",
    "    # Partial derivatives\n",
    "    df_dalpha = (A * ln_term) / (C - B)\n",
    "    df_dalpha_NT = ((A - B) * ln_term) / (C - B)\n",
    "\n",
    "    # Total uncertainty\n",
    "    sigma_f = np.sqrt((df_dalpha * unc) ** 2 + (df_dalpha_NT * sigma_alpha_NT) ** 2)\n",
    "    \n",
    "    return sigma_f \n",
    "\n",
    "thermalfractions=[]\n",
    "thermalfractionserrs=[]\n",
    "\n",
    "for row in table:\n",
    "    if math.isnan(row['alpha1']) == True:\n",
    "        thermalfractions.append(x)\n",
    "        thermalfractionserrs.append(x)\n",
    "    else:\n",
    "        thermalfractions.append(tfrac(row['alpha1']))\n",
    "        thermalfractionserrs.append(tfrac_unc(row['alpha1'],row['b1']))\n",
    "\n",
    "# results2=Column(tfrac_unc(table['alpha1'],table['b1']),name='error')\n",
    "results1=Column(thermalfractions,name='data')\n",
    "results2=Column(thermalfractionserrs,name='error')\n",
    "tbl=Table([table['source ID'],results1,results2])\n",
    "print(tbl[:10])\n",
    "\n",
    "# tbl.write('/users/adignan/tfrac_july.csv',overwrite=True)\n",
    "# print(np.median(results1))\n",
    "# print(np.std(results1))\n",
    "# print(median_absolute_deviation(results1))\n",
    "# print(median_absolute_deviation(results2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
